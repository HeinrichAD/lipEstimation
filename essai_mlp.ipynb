{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0406d2a2",
   "metadata": {},
   "source": [
    "# Advanced topics in Deep Learning\n",
    "## Lipschitz regularity of deep neural networks: analysis and efficient estimation\n",
    "\n",
    "*Jean-Baptiste BAITAIRIAN and Thomas LE ROUX*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6af69f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of all packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "297b0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the random seeds to ensure reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543327fe",
   "metadata": {},
   "source": [
    "### Database creation (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45855eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: models/data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We import the train set. Set 'dowload' to True if we do not already have the dataset\n",
    "Transform = transforms.ToTensor()\n",
    "train = datasets.MNIST(root='models/data', train=True, download=False, transform=Transform)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdab3aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: models/data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We import the test set. Set 'dowload' to True if we do not already have the dataset\n",
    "test = datasets.MNIST(root='models/data', train=False, download=False, transform=Transform)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6595201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28]) \n",
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# We print the shape of the first training data and its label\n",
    "image, label = train[0]\n",
    "print('Shape:', image.shape, '\\nLabel:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f99014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1240a2b6ac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We plot the first training data\n",
    "plt.imshow(image.reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7febcc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create DataLoaders for our train and test sets\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5051a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP neural network with 1-Lipschitz activation functions\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size=784, output_size=10, layers=[120, 84]):\n",
    "        super().__init__()\n",
    "        self.d1 = nn.Linear(input_size, layers[0])\n",
    "        self.d2 = nn.Linear(layers[0], layers[1])\n",
    "        self.d3 = nn.Linear(layers[1], output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.d1(X))\n",
    "        X = F.relu(self.d2(X))\n",
    "        X = self.d3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8c56d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (d1): Linear(in_features=784, out_features=20, bias=True)\n",
      "  (d2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (d3): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# We create our model: an MLP with (20, 20, 10) neurons\n",
    "model = MultilayerPerceptron(layers=[20, 20])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bebf03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the criterion and the optimizer to use\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdfd6f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Batch:  600 [ 60000/60000] | Train loss: 0.28381541 | Train accuracy: 81.257%\n",
      "Epoch:  1 | Batch:  600 [ 60000/60000] | Train loss: 0.31789720 | Train accuracy: 91.713%\n",
      "Epoch:  2 | Batch:  600 [ 60000/60000] | Train loss: 0.36529517 | Train accuracy: 92.972%\n",
      "Epoch:  3 | Batch:  600 [ 60000/60000] | Train loss: 0.23695387 | Train accuracy: 93.800%\n",
      "Epoch:  4 | Batch:  600 [ 60000/60000] | Train loss: 0.19439988 | Train accuracy: 94.352%\n",
      "Epoch:  5 | Batch:  600 [ 60000/60000] | Train loss: 0.16365018 | Train accuracy: 94.762%\n",
      "Epoch:  6 | Batch:  600 [ 60000/60000] | Train loss: 0.11883107 | Train accuracy: 95.120%\n",
      "Epoch:  7 | Batch:  600 [ 60000/60000] | Train loss: 0.26943505 | Train accuracy: 95.402%\n",
      "Epoch:  8 | Batch:  600 [ 60000/60000] | Train loss: 0.05913188 | Train accuracy: 95.598%\n",
      "Epoch:  9 | Batch:  600 [ 60000/60000] | Train loss: 0.12871434 | Train accuracy: 95.873%\n"
     ]
    }
   ],
   "source": [
    "# We train our MLP\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "        \n",
    "        y_pred = model(X_train.view(100, -1))\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b%600 == 0:\n",
    "            print(f'Epoch: {i:2} | Batch: {b:4} [{100*b:6}/60000] | Train loss: {loss.item():10.8f} | Train accuracy: {trn_corr.item()*100/60000:.3f}%')\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            y_val = model(X_test.view(500, -1))\n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "    \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32442646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.360%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy: {test_correct[-1].item()*100/10000:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a8619",
   "metadata": {},
   "source": [
    "### Frobenius upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ba86a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of first layer = 20.201963424682617\n",
      "Frobenius norm of second layer = 5.598930835723877\n",
      "Frobenius norm of third layer = 4.646459102630615\n"
     ]
    }
   ],
   "source": [
    "# We compute the norm of each layer\n",
    "nrm_fro1 = torch.linalg.norm(model.d1.weight, ord='fro')\n",
    "nrm_fro2 = torch.linalg.norm(model.d2.weight, ord='fro')\n",
    "nrm_fro3 = torch.linalg.norm(model.d3.weight, ord='fro')\n",
    "\n",
    "print('Frobenius norm of first layer =', nrm_fro1.item())\n",
    "print('Frobenius norm of second layer =', nrm_fro2.item())\n",
    "print('Frobenius norm of third layer =', nrm_fro3.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cd48939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius upper bound = 525.5581665039062\n"
     ]
    }
   ],
   "source": [
    "# We compute the Frobenius upper bound\n",
    "L_hat_Fro = nrm_fro1 * nrm_fro2 * nrm_fro3\n",
    "print('Frobenius upper bound =', L_hat_Fro.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c63ff",
   "metadata": {},
   "source": [
    "### AutoLip upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a97a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral norm of first layer = 8.5597505569458\n",
      "Spectral norm of second layer = 2.48268985748291\n",
      "Spectral norm of third layer = 2.007674217224121\n"
     ]
    }
   ],
   "source": [
    "# We compute the norm of each layer\n",
    "nrm1 = torch.linalg.norm(model.d1.weight, ord=2)\n",
    "nrm2 = torch.linalg.norm(model.d2.weight, ord=2)\n",
    "nrm3 = torch.linalg.norm(model.d3.weight, ord=2)\n",
    "\n",
    "print('Spectral norm of first layer =', nrm1.item())\n",
    "print('Spectral norm of second layer =', nrm2.item())\n",
    "print('Spectral norm of third layer =', nrm3.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c7c490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoLip upper bound = 42.665496826171875\n"
     ]
    }
   ],
   "source": [
    "# We compute the AutoLip upper bound\n",
    "L_hat_AL = nrm1 * nrm2 * nrm3\n",
    "print('AutoLip upper bound =', L_hat_AL.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b78138",
   "metadata": {},
   "source": [
    "### SeqLip upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7f86c",
   "metadata": {},
   "source": [
    "We can use a brute force combinatorial approach to compute the SeqLip upper bound given by formula (8) of the paper because we have small layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32f64ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the SVD of our matrices\n",
    "U1, S1, Vh1 = torch.linalg.svd(model.d1.weight, full_matrices=False)  # Be careful, Vh1 is the transpose conjugate of V1\n",
    "U2, S2, Vh2 = torch.linalg.svd(model.d2.weight, full_matrices=False)\n",
    "U3, S3, Vh3 = torch.linalg.svd(model.d3.weight, full_matrices=False)\n",
    "\n",
    "# We transform S1, S2 and S3 into diagonal matrices\n",
    "Sigma1 = torch.diag(S1)\n",
    "Sigma2 = torch.diag(S2)\n",
    "Sigma3 = torch.diag(S3)\n",
    "\n",
    "# We compute the square root of Sigma2\n",
    "Sigma2_sqrt = torch.Tensor(sqrtm(Sigma2.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1387f72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1: torch.Size([20, 20])\n",
      "U2: torch.Size([20, 20])\n",
      "U3: torch.Size([10, 10])\n",
      "Sigma1: torch.Size([20, 20])\n",
      "Sigma2: torch.Size([20, 20])\n",
      "Sigma3: torch.Size([10, 10])\n",
      "Vh1: torch.Size([20, 784])\n",
      "Vh2: torch.Size([20, 20])\n",
      "Vh3: torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# We print the shapes of our matrices\n",
    "print('U1:', U1.shape)\n",
    "print('U2:', U2.shape)\n",
    "print('U3:', U3.shape)\n",
    "print('Sigma1:', Sigma1.shape)\n",
    "print('Sigma2:', Sigma2.shape)\n",
    "print('Sigma3:', Sigma3.shape)\n",
    "print('Vh1:', Vh1.shape)\n",
    "print('Vh2:', Vh2.shape)\n",
    "print('Vh3:', Vh3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720258da",
   "metadata": {},
   "source": [
    "We will use the $\\verb+product()+$ function from $\\verb+itertools+$ in order to get all the possible lists of a certain length containing only 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce3f9b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0),\n",
       " (0, 0, 1),\n",
       " (0, 1, 0),\n",
       " (0, 1, 1),\n",
       " (1, 0, 0),\n",
       " (1, 0, 1),\n",
       " (1, 1, 0),\n",
       " (1, 1, 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of use of product()\n",
    "# Allows to have all combinations of 0s and 1s in a vector of length n_i\n",
    "n_i = 3\n",
    "# This list contains tuples that we can convert to a list thanks to list() or to a Tensor thanks to torch.Tensor()\n",
    "list(product(range(2), repeat=n_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b990b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1048576/1048576 [02:19<00:00, 7534.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# We maximize the first factor by a brute force combinatorial approach\n",
    "n1 = U1.shape[0]  # 20, so we have 2^20 = 1 048 576 combinations to test\n",
    "norm1_best = 0  # Will contain the maximum norm\n",
    "\n",
    "for sigma2_tuple in tqdm(list(product(range(2), repeat=n1))):\n",
    "    diag_sig2 = torch.diag(torch.Tensor(sigma2_tuple))  # We compute the diagonal matrix\n",
    "    mat_prod_1 = Sigma2_sqrt @ Vh2 @ diag_sig2 @ U1 @ Sigma1\n",
    "    norm1 = torch.linalg.norm(mat_prod_1, ord=2)\n",
    "    \n",
    "    if norm1 > norm1_best:\n",
    "        norm1_best = norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45b2301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max norm1 = 10.403834342956543\n"
     ]
    }
   ],
   "source": [
    "# We print the best (biggest) norm for the first factor\n",
    "print('Max norm1 =', norm1_best.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f208fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1048576/1048576 [01:52<00:00, 9352.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# We maximize the second factor by a brute force combinatorial approach\n",
    "n2 = U2.shape[0]  # 20, so we have 2^20 = 1 048 576 combinations to test\n",
    "norm2_best = 0  # Will contain the maximum norm\n",
    "\n",
    "for sigma3_tuple in tqdm(list(product(range(2), repeat=n2))):\n",
    "    diag_sig3 = torch.diag(torch.Tensor(sigma3_tuple))  # We compute the diagonal matrix\n",
    "    mat_prod_2 = Sigma3 @ Vh3 @ diag_sig3 @ U2 @ Sigma2_sqrt\n",
    "    norm2 = torch.linalg.norm(mat_prod_2, ord=2)\n",
    "    \n",
    "    if norm2 > norm2_best:\n",
    "        norm2_best = norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acede6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max norm2 = 2.766519069671631\n"
     ]
    }
   ],
   "source": [
    "# We print the best (biggest) norm for the second factor\n",
    "print('Max norm2 =', norm2_best.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecf20c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqLip upper bound = 28.782405853271484\n"
     ]
    }
   ],
   "source": [
    "# We compute the SeqLip upper bound\n",
    "L_hat_SL = norm1_best * norm2_best\n",
    "print('SeqLip upper bound =', L_hat_SL.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5df2a9",
   "metadata": {},
   "source": [
    "### Comparison of Frobenius, AutoLip and SeqLip upper bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff7a37",
   "metadata": {},
   "source": [
    "The Frobenius upper bound clearly overestimates the Lispchitz constant of the MLP. On the contrary, SeqLip and AutoLip upper bounds are closer to the real Lipschitz constant and, in particular, SeqLip upper bound is lower than AutoLip upper bound for an MLP with ReLU activation functions. Therefore, SeqLip seems to improve the upper bound on the Lipschitz constant compared to AutoLip, as said in the article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11921060",
   "metadata": {},
   "source": [
    "Formula (10) of the paper allows to compare $\\hat L_{AL}$ and $\\hat L_{SL}$ (under certain assumptions that we will consider true to see if the order of magnitude is approximately respected):\n",
    "$$\n",
    "\\hat L_{SL} \\approx \\frac{\\hat L_{AL}}{\\pi^{K-1}} \\Leftrightarrow \\frac{\\hat L_{AL}}{\\hat L_{SL}} \\approx \\pi^{K-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3c33aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_AL/L_SL = 1.4823464155197144\n",
      "pi^{K-1} = 9.869604401089358\n"
     ]
    }
   ],
   "source": [
    "# In our case, K = 3 (number of simple operations, i.e. linear layers)\n",
    "K = 3\n",
    "\n",
    "L_hat_ratio = L_hat_AL / L_hat_SL\n",
    "second_term = np.pi ** (K-1)\n",
    "\n",
    "print('L_AL/L_SL =', L_hat_ratio.item())\n",
    "print('pi^{K-1} =', second_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5eb71",
   "metadata": {},
   "source": [
    "Of course, the two terms are not exactly the same because all the assumptions that led to (10) are not verified, but it still gives an idea of the ratio between $\\hat L_{AL}$ and $\\hat L_{SL}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d925d6",
   "metadata": {},
   "source": [
    "### AutoGrad compliant power method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc754e",
   "metadata": {},
   "source": [
    "In this section, we implement and test a simpler version of the AutoGrad compliant power method (given by algorithm 2 in the article) on a linear function $f$. To define our function, we simply use the weights obtained by the first linear layer of our MLP and we call them M1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a541276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1: torch.Size([20, 784])\n"
     ]
    }
   ],
   "source": [
    "M1 = model.d1.weight\n",
    "print('M1:', M1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "040192db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our affine function f\n",
    "# x must be of length 784\n",
    "def f(x):\n",
    "    return M1 @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fa727c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simpler version of AutoGrad compliant power method (without automatic differentiation) applied to an afine function\n",
    "def AG_power_method(f, M, v_init, N=10):\n",
    "    v = v_init\n",
    "    L_evol = []\n",
    "    \n",
    "    for k in range(N):\n",
    "        v = M.T @ M @ v\n",
    "        lmda = torch.linalg.norm(v)\n",
    "        v = v / lmda\n",
    "        \n",
    "        # We store the different values of L(f) that are estimated\n",
    "        L = torch.linalg.norm(f(v) - f(torch.zeros(v.shape[0]))).detach().numpy()  # In our case, f(0)=0, but we keep it\n",
    "        L_evol.append(L)\n",
    "    return L, L_evol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b0c623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 8.5597515\n",
      "L2 = 8.559752\n",
      "L3 = 8.559752\n"
     ]
    }
   ],
   "source": [
    "# We run 3 different simulations to evaluate the effect of the initialization\n",
    "N_iter = 100  # Number of iterations\n",
    "\n",
    "# Three different initializations\n",
    "v_init1 = torch.randint(-10, 10, (M1.shape[1],), dtype=torch.float)\n",
    "v_init2 = torch.randint(-10, 10, (M1.shape[1],), dtype=torch.float)\n",
    "v_init3 = torch.randint(-10, 10, (M1.shape[1],), dtype=torch.float)\n",
    "\n",
    "# We run 3 different simulations\n",
    "L1, L_evol1 = AG_power_method(f, M1, v_init1, N=N_iter)\n",
    "L2, L_evol2 = AG_power_method(f, M1, v_init2, N=N_iter)\n",
    "L3, L_evol3 = AG_power_method(f, M1, v_init3, N=N_iter)\n",
    "\n",
    "# We print the 3 Lipschitz constant estimations\n",
    "print('L1 =', L1)\n",
    "print('L2 =', L2)\n",
    "print('L3 =', L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0062618",
   "metadata": {},
   "source": [
    "We can note that our result are really close to the spectral norm of the first layer of our MLP. This is not surprising because the Lipschitz constant of an affine function $f : x \\mapsto Mx + b $, with $M \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^m$, is the largest singular value of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b3a5742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We plot the evolution of the estimated Lipschitz constant with 3 different initializations\n",
    "plt.plot(L_evol1, label='Initialization 1')\n",
    "plt.plot(L_evol2, label='Initialization 2')\n",
    "plt.plot(L_evol3, label='Initialization 3')\n",
    "plt.ylabel('Estimation of the Lipschitz constant')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.title('Evolution of the estimated Lipschitz constant with 3 different initializations')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694391d3",
   "metadata": {},
   "source": [
    "As we can see, the initialization of the power method has an effect on the estimation, but the more the number of iterations is large, the more the estimations with different initializations become similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
